{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPXzvlWawQgP65ALSIQMxQN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/marcoweb/colab-indexacao/blob/main/ColetaDeArtigos_Embrapa.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importação das bibiotecas"
      ],
      "metadata": {
        "id": "zGWCs3Uyb-Cm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qZQ1Bx9AlzGc"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import urllib\n",
        "import pandas\n",
        "import requests\n",
        "from bs4 import BeautifulSoup"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Busca os dados das revistas na base de dados da embrapa e baixa os arquivos xls com as informações dos artigos"
      ],
      "metadata": {
        "id": "6tLtAQIP127R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embrapaFilesPath = 'embrapaSource/'\n",
        "if not os.path.exists(embrapaFilesPath):\n",
        "  os.mkdir(embrapaFilesPath)\n",
        "dfRevistas = pandas.read_excel('revistas.xlsx')\n",
        "for item in dfRevistas.to_dict('records'):\n",
        "  embrapaUrl = 'https://www.bdpa.cnptia.embrapa.br/consulta/busca?b=ad&busca=((fonte-imprenta:%22'+urllib.parse.quote(item['revista'])+'%22))&qFacets=(((fonte-imprenta:%22'+urllib.parse.quote(item['revista'])+'%22)))%20%20AND%20((idioma:%22Ingl%C3%AAs%22))&biblioteca=vazio&sort=&paginacao=t&paginaAtual=1&ig=tn'\n",
        "  fileData = requests.get(embrapaUrl).content\n",
        "  with open(embrapaFilesPath + str(item['id']) + '.xls', 'wb') as handler:\n",
        "    handler.write(fileData)\n"
      ],
      "metadata": {
        "id": "9CKiuPtKugwW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lê os dados dos arquivos xls contendo as informações dos artigos da Embrapa criando um dataframe com as informações relevantes (Título, Ano de Publicação, Thesaurus Nal)"
      ],
      "metadata": {
        "id": "GiVCOQYfcJRf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dfValidPapers = pandas.DataFrame();\n",
        "for item in dfRevistas.to_dict('records'):\n",
        "  fileName = embrapaFilesPath + str(item['id']) + '.xls'\n",
        "  dfTemp = pandas.read_excel(fileName, skiprows=4)\n",
        "  dfDadosEmbrapa = dfTemp[(dfTemp['Thesaurus Nal'].notna()) & (dfTemp['Ano de publicação'] >= 2017)][['Título', 'Thesaurus Nal', 'Ano de publicação']].sort_values(by=['Ano de publicação'])\n",
        "  dfValidPapers = pandas.concat([dfValidPapers, dfDadosEmbrapa], ignore_index=True)\n",
        "dfValidPapers['Título'] = dfValidPapers['Título'].apply(lambda x: \" \".join(x.split()).removesuffix('.'))"
      ],
      "metadata": {
        "id": "9Ph3zdNi2T0O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Acessa a página no Redalyc das revistas coletando as urls para acesso às coleções de artigos por ano de pulicação"
      ],
      "metadata": {
        "id": "2_LvXSyecanc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "listUrls = {}\n",
        "for revista in dfRevistas.to_dict('records'):\n",
        "  redalycUrl = 'https://www.redalyc.org/revista.oa?id=' + str(revista['id'])\n",
        "  req = requests.get(redalycUrl)\n",
        "  html = req.text\n",
        "  soup = BeautifulSoup(html, 'html.parser')\n",
        "  listUrls[str(revista['id'])] = {}\n",
        "  for item in soup.find_all('label', attrs={'class': 'anio-numeros'}):\n",
        "    year = item.find('span').text\n",
        "    if year not in listUrls[str(revista['id'])].keys():\n",
        "      if int(year) >= 2017:\n",
        "        listUrls[str(revista['id'])][year] = item.find('a')['href']"
      ],
      "metadata": {
        "id": "Wt3mbtke-4Hp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Verifica se os artigos existentes no redalyc contem os metadados selecionados na Embrapa fazendo o download do XML quando disponível."
      ],
      "metadata": {
        "id": "RozniJDcc3_b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "basePath = 'files/'\n",
        "if not os.path.exists(basePath):\n",
        "  os.mkdir(basePath)\n",
        "\n",
        "goldIndexing = []\n",
        "for id, data in listUrls.items():\n",
        "  for year, url in data.items():\n",
        "    dfValidPapersByYear = dfValidPapers[dfValidPapers['Ano de publicação'] == int(year)]\n",
        "    if dfValidPapersByYear.size > 0:\n",
        "      redalycContentHtml = BeautifulSoup(requests.get(url).text, 'html.parser')\n",
        "      for article in redalycContentHtml.find_all('div', attrs={'class': 'articuloN'}):\n",
        "        articleName = \" \".join(article.find('b', attrs={'class': 'tituloArt'}).text.split())\n",
        "        if dfValidPapersByYear.isin([articleName]).any().any():\n",
        "          for link in article.find('div', attrs={'class': 'links'}).find_all('a'):\n",
        "            if link['href'].endswith('.xml'):\n",
        "              fileId = 'D' + str((len(goldIndexing) + 1))\n",
        "              fileData = requests.get('https://www.redalyc.org/' + link['href']).content\n",
        "              xml = BeautifulSoup(fileData, 'xml')\n",
        "              if xml.find('article')['xml:lang'] == 'en':\n",
        "                fileName = basePath + fileId + '-' + articleName.replace('/', '_') + '.xml'\n",
        "                with open(fileName, 'wb') as handler:\n",
        "                  handler.write(fileData)\n",
        "                goldIndexing.append({'id': fileId, 'title': articleName, 'indexing': dfValidPapersByYear.loc[dfValidPapersByYear['Título'] == articleName]['Thesaurus Nal'].item().removesuffix('.').replace(';', ',')})"
      ],
      "metadata": {
        "id": "44CEdn2HGhn3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cria dos arquivos com a lista de artigos baixados e gold indexing."
      ],
      "metadata": {
        "id": "Lz9auhsOdII8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(basePath + \"gold_indexing.txt\", \"w\") as gi:\n",
        "  with open(basePath + \"_articles.txt\", \"w\") as articles:\n",
        "    for item in goldIndexing:\n",
        "      gi.write(item['id'] + ': ' + item['indexing'] + \"\\n\")\n",
        "      articles.write(item['id'] + ': ' + item['title'] + \"\\n\")"
      ],
      "metadata": {
        "id": "OacxMT-JTLyN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compacta os arquivos para download"
      ],
      "metadata": {
        "id": "x4WeSYJDkL-M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import glob\n",
        "\n",
        "with zipfile.ZipFile('corpus.zip', 'w') as zip:\n",
        "   for file in glob.glob(basePath + '*'):\n",
        "        zip.write(file)"
      ],
      "metadata": {
        "id": "Ce6QSTd8gG69"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}